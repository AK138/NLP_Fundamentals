{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook revists Pyohio2018 Natural Language Processing in Python\n",
    "<br> Credit goes to https://github.com/adashofdata/nlp-in-python-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, all of the analysis we've done has been generic - counting, creating scatter plots and wordclouds, etc. \n",
    "\n",
    "When it comes to text data, there are a few popular techniques - sentiment analysis. \n",
    "<br>\n",
    "Below is a few key points to remember with sentiment analysis.\n",
    "\n",
    "1. **TextBlob Module:** Linguistic researchers have labeled the sentiment of words based on their domain expertise. Sentiment of words can vary based on where it is in a sentence. The TextBlob module allows us to take advantage of these labels.\n",
    "2. **Sentiment Labels:** Each word in a corpus is labeled in terms of polarity and subjectivity (there are more labels as well, but we're going to ignore them for now). A corpus' sentiment is the average of these.\n",
    "   * **Polarity**: How positive or negative a word is. -1 is very negative. +1 is very positive.\n",
    "   * **Subjectivity**: How subjective, or opinionated a word is. 0 is fact. +1 is very much an opinion. Though \"Stating subjectivity itself might be subjective\".\n",
    "\n",
    "For more info on how TextBlob coded up its [sentiment function](https://planspace.org/20150607-textblob_sentiment/).\n",
    "\n",
    "Let's take a look at the sentiment of the various transcripts, both overall and throughout the comedy routine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment of Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with reading the corpus\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle('corpus.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lambda functions to find the polarity and subjectivity of each Transcript\n",
    "# Reading for lambda function=> https://dbader.org/blog/python-lambda-functions\n",
    "# Install textblob with Terminal/Anaconda Navigator: conda install -c conda-forge textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "# Apply the polarity and subjectivity to the data\n",
    "data['Polarity'] = data['Transcript'].apply(pol)\n",
    "data['Subjectivity'] = data['Transcript'].apply(sub)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "for index, comedian in enumerate(data.index):\n",
    "    x = data.Polarity.loc[comedian]\n",
    "    y = data.Subjectivity.loc[comedian]\n",
    "    '''Pandas DataFrame.loc attribute access a group of rows and columns \n",
    "    by label(s) or a boolean array in the given DataFrame.'''\n",
    "    plt.scatter(x, y, color='blue')\n",
    "    plt.text(x+.001, y+.001, data['Full_name'][index], fontsize=10)\n",
    "    #plt.text(x, y, data['Full_name'][index], fontsize=10)\n",
    "    plt.xlim(-.01, .12) # Set the x limits of the current axes\n",
    "    \n",
    "plt.title('Sentiment Analysis', fontsize=15)\n",
    "plt.xlabel('<-- Negative ----[Polarity]---- Positive -->', fontsize=15)\n",
    "plt.ylabel('<-- Facts ----[Subjectivity]---- Opinions -->', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment of Routine Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of looking at the overall sentiment, let's see if there's anything interesting about the sentiment over time throughout each routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each routine into 10 parts\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def split_text(text, n=10):\n",
    "    '''Takes in a string of text and splits into n equal parts, \n",
    "       with a default of 10 equal parts.'''\n",
    "\n",
    "    \"\"\" Calculate \n",
    "      - length of text,\n",
    "      - the size of each chunk of text, \n",
    "      - and the starting points of each chunk of text\"\"\"\n",
    "    length = len(text)\n",
    "    size = math.floor(length / n)\n",
    "    start = np.arange(0, length, size)\n",
    "    \n",
    "    # Pull out equally sized pieces of text and put it into a list\n",
    "    split_list = []\n",
    "    for piece in range(n):\n",
    "        split_list.append(text[start[piece]:start[piece]+size])\n",
    "    return split_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at our data again\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's create a list to hold all of the pieces of text\n",
    "list_pieces_p = []\n",
    "for tp in data.Transcript:\n",
    "    splitp = split_text(tp)\n",
    "    list_pieces_p.append(splitp)\n",
    "    \n",
    "list_pieces_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_pieces_p)\n",
    "# The list has 12 elements (commedians), one for each transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each transcript has been split into 10 pieces of text\n",
    "len(list_pieces_p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the polarity for each piece of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the polarity for each piece of text\n",
    "\n",
    "polarity_transcript = []\n",
    "for lp in list_pieces_p:\n",
    "    polarity_piece = []\n",
    "    for p in lp:\n",
    "        polarity_piece.append(TextBlob(p).sentiment.polarity)\n",
    "    polarity_transcript.append(polarity_piece)\n",
    "    \n",
    "polarity_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the plot of Ali Wong's polarity\n",
    "plt.plot(polarity_transcript[0])\n",
    "plt.title(data['Full_name'].index[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the plot for all comedians\n",
    "plt.rcParams['figure.figsize'] = [16, 12]\n",
    "\n",
    "for index, comedian in enumerate(data.index):    \n",
    "    plt.subplot(3, 4, index+1)\n",
    "    plt.plot(polarity_transcript[index])\n",
    "    xmin, xmax = 0, 9\n",
    "    plt.hlines([0], xmin, xmax, \"orange\", linestyles='solid') \n",
    "    plt.title(data['Full_name'][index])\n",
    "    plt.ylim(ymin=-.2, ymax=.3)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ali Wong stays generally positive throughout her routine. Similar comedians are Louis C.K. and Mike Birbiglia.\n",
    "\n",
    "On the other hand, we can see the different patterns in Bo Burnham who gets positive as time passes, and Dave Chappelle who has some pretty down moments in his routine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the subjectivity for each piece of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a list to hold all of the pieces of text\n",
    "list_pieces_s = []\n",
    "for ts in data.Transcript:\n",
    "    splits = split_text(ts)\n",
    "    list_pieces_s.append(splits)\n",
    "    \n",
    "list_pieces_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity_transcript = []\n",
    "for lp2 in list_pieces_s:\n",
    "    subjectivity_piece = []\n",
    "    for ps in lp2:\n",
    "        subjectivity_piece.append(TextBlob(ps).sentiment.subjectivity)\n",
    "    subjectivity_transcript.append(subjectivity_piece)\n",
    "    \n",
    "subjectivity_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the plot for all comedians\n",
    "plt.rcParams['figure.figsize'] = [16, 12]\n",
    "\n",
    "for index, comedian in enumerate(data.index):    \n",
    "    plt.subplot(3, 4, index+1)\n",
    "    plt.plot(subjectivity_transcript[index])\n",
    "    #plt.plot(polarity_transcript[index])\n",
    "    xmin, xmax = 0, 9\n",
    "    plt.hlines([0.5], xmin, xmax, \"orange\", linestyles='solid') \n",
    "    \n",
    "    plt.plot(np.arange(0,10), np.zeros(10))\n",
    "    \n",
    "    plt.title(data['Full_name'][index])\n",
    "    plt.ylim(ymin=.2, ymax=.8)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the patterns in Joe Rogan who gets subjective as time passes in his routine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
